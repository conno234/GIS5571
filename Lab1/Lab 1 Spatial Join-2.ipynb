{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopandas\n",
      "  Downloading geopandas-0.14.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from geopandas) (21.3)\n",
      "Requirement already satisfied: fiona>=1.8.21 in /opt/conda/lib/python3.9/site-packages (from geopandas) (1.8.21)\n",
      "Requirement already satisfied: shapely>=1.8.0 in /opt/conda/lib/python3.9/site-packages (from geopandas) (1.8.4)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /opt/conda/lib/python3.9/site-packages (from geopandas) (1.4.4)\n",
      "Collecting pyproj>=3.3.0\n",
      "  Downloading pyproj-3.6.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click-plugins>=1.0 in /opt/conda/lib/python3.9/site-packages (from fiona>=1.8.21->geopandas) (1.1.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from fiona>=1.8.21->geopandas) (65.6.3)\n",
      "Requirement already satisfied: six>=1.7 in /opt/conda/lib/python3.9/site-packages (from fiona>=1.8.21->geopandas) (1.16.0)\n",
      "Requirement already satisfied: munch in /opt/conda/lib/python3.9/site-packages (from fiona>=1.8.21->geopandas) (2.5.0)\n",
      "Requirement already satisfied: attrs>=17 in /opt/conda/lib/python3.9/site-packages (from fiona>=1.8.21->geopandas) (22.1.0)\n",
      "Requirement already satisfied: click>=4.0 in /opt/conda/lib/python3.9/site-packages (from fiona>=1.8.21->geopandas) (8.0.4)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/conda/lib/python3.9/site-packages (from fiona>=1.8.21->geopandas) (0.7.2)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.9/site-packages (from fiona>=1.8.21->geopandas) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.4.0->geopandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.4.0->geopandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.4.0->geopandas) (1.22.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->geopandas) (3.0.9)\n",
      "Installing collected packages: pyproj, geopandas\n",
      "Successfully installed geopandas-0.14.0 pyproj-3.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# For running in ArcGIS Online/Pro\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we will import the needed packages for this notebook\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import arcpy\n",
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import urllib3\n",
    "import os \n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since some of the APIs may require certificate authorization, we'll use the below code to get around that.\n",
    "urllib3.disable_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = r\"https://gisdata.mn.gov/api/3/action/package_show?id=us-mn-state-metc-bdry-census2020counties-ctus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(api_url, verify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next, we will convert the response to a json\n",
    "json=response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional: uncomment the below code to check the json.\n",
    "#json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded shp_bdry_census2020counties_ctus.zip\n"
     ]
    }
   ],
   "source": [
    "# Our next step is get the zip file link from the dictionary in the json associated with the shapefile package.\n",
    "# Since, all the files are under the resources list, we first need to extract that list from the json.\n",
    "resources = json['result']['resources']\n",
    "\n",
    "# Next, we will iterate through the resources to find the one with format 'SHP'.\n",
    "for resource in resources:\n",
    "    if resource['format'] == 'SHP':\n",
    "        #Once we find the shapefile, we can save the associated URL.\n",
    "        zip_url = resource['url']\n",
    "        #Next, we can save the zip_url to our directory as a zip file.\n",
    "        zip_filename = os.path.basename(zip_url)\n",
    "\n",
    "        # We can finally download the zip file and produce some code that can will generate a text output indicating the name of the file we have downloaded.\n",
    "        response = requests.get(zip_url)\n",
    "        if response.status_code == 200:\n",
    "            with open(zip_filename, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"Downloaded {zip_filename}\")\n",
    "        else:\n",
    "            print(f\"Failed to download {zip_filename}. Status code: {response.status_code}\")\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  shp_bdry_census2020counties_ctus.zip\n",
      "  inflating: Census2020CTUs.prj      \n",
      "  inflating: Census2020CountiesAndCTUs.dbf  \n",
      "  inflating: Census2020Counties.prj  \n",
      "  inflating: Census2020CountiesAndCTUs__ATTACH.dbf.xml  \n",
      "  inflating: Census2020Counties.shp  \n",
      "  inflating: Census2020CTUs.shp.xml  \n",
      "  inflating: Census2020CountiesAndCTUs.shp  \n",
      "  inflating: Census2020CountiesAndCTUs.cpg  \n",
      "  inflating: Census2020CountiesAndCTUs.sbn  \n",
      "  inflating: Census2020CountiesAndCTUs.shp.xml  \n",
      "  inflating: Census2020Counties.shx  \n",
      "  inflating: Census2020CTUs.sbx      \n",
      "  inflating: Census2020Counties.cpg  \n",
      "  inflating: Census2020CTUs.dbf      \n",
      "  inflating: Census2020Counties.dbf  \n",
      "  inflating: Census2020CountiesAndCTUs.shx  \n",
      "  inflating: Census2020Counties.sbx  \n",
      "  inflating: Census2020CountiesAndCTUs__ATTACH.cpg  \n",
      "  inflating: Census2020CountiesAndCTUs__ATTACH.dbf  \n",
      "  inflating: Census2020CTUs.sbn      \n",
      "  inflating: Census2020Counties.shp.xml  \n",
      "  inflating: Census2020CTUs.shx      \n",
      "  inflating: Census2020CTUs.shp      \n",
      "  inflating: Census2020CountiesAndCTUs.prj  \n",
      "  inflating: Census2020CTUs.cpg      \n",
      "  inflating: Census2020Counties.sbn  \n",
      "  inflating: Census2020CountiesAndCTUs.sbx  \n",
      "  inflating: metadata/metadata.html  \n",
      "  inflating: metadata/metadata.xml   \n"
     ]
    }
   ],
   "source": [
    "#Next, we unzip the downloaded file to see the associated packages.\n",
    "!unzip shp_bdry_census2020counties_ctus.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once we find the shp file from the downloaded shapefile, we can load our shapefile.\n",
    "shapefile_path = 'Census2020Counties.shp'\n",
    "#Using Geopandas, we can then save our shapefile as a geodataframe.\n",
    "gdf = gpd.read_file(shapefile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next, we can work on summoning our second set of data using the Google Places API.\n",
    "#First, let's save out API key to a specific variable.\n",
    "api_key = 'YOUR KEY HERE'\n",
    "\n",
    "#Next we can load the base API URL without the API key, including the type of command we wish to perform.\n",
    "#In this case, it's a \"find place from text\" command.\n",
    "#We will also be calling our API request in the form of a json.\n",
    "base_url = \"https://maps.googleapis.com/maps/api/place/findplacefromtext/json\"\n",
    "\n",
    "#We then want to define the parameters for the request.\n",
    "params = {\n",
    "    #I want to gather address, place names, and the coordinates of our requested locations.\n",
    "    'fields': 'formatted_address,name,geometry',\n",
    "    #We will set the keyword we will be looking for and the type of input.\n",
    "    'input': 'starbuck',\n",
    "    'inputtype': 'textquery',\n",
    "    #Finally, we will look for locations using a location bias. In this case, it's a 3000 meter radius around the Universtiy of Minnesota.\n",
    "    'locationbias': 'circle:3000@44.974,-93.2277',\n",
    "    'key': api_key  # The variable for our API key goes here.\n",
    "}\n",
    "\n",
    "#Finally, we can make the API request\n",
    "response_2 = requests.get(base_url, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Like the first dataset, we will save our API request as a JSON\n",
    "json_2 = response_2.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'candidates': [{'formatted_address': '713 S Washington Ave Ste 101, Minneapolis, MN 55415, United States',\n",
       "   'geometry': {'location': {'lat': 44.9771689, 'lng': -93.2579907},\n",
       "    'viewport': {'northeast': {'lat': 44.97862397989272,\n",
       "      'lng': -93.25665747010729},\n",
       "     'southwest': {'lat': 44.97592432010728, 'lng': -93.25935712989272}}},\n",
       "   'name': 'Starbucks'}],\n",
       " 'status': 'OK'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Optional: uncomment this code to take a look at json_2\n",
    "#json_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_143/1266975707.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  marker_gdf = marker_gdf.append({'name': name, 'formatted_address': formatted_address, 'geometry': point}, ignore_index=True)\n",
      "/opt/conda/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:122: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  arr = construct_1d_object_array_from_listlike(values)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>formatted_address</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>713 S Washington Ave Ste 101, Minneapolis, MN ...</td>\n",
       "      <td>POINT (-93.25799 44.97717)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name                                  formatted_address  \\\n",
       "0  Starbucks  713 S Washington Ave Ste 101, Minneapolis, MN ...   \n",
       "\n",
       "                     geometry  \n",
       "0  POINT (-93.25799 44.97717)  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We now need to extract the geometry of the location. To keep things simple we will use only the first set of coordinates.\n",
    "#Let's first create a new geodataframe that will keep track of a place's name, address, and coordinates.\n",
    "marker_gdf = gpd.GeoDataFrame(columns=['name', 'formatted_address', 'geometry'])\n",
    "\n",
    "#Next we need to look through the json's candidates list to find the needed coordinates under geometry.\n",
    "for candidate in json_2['candidates']:\n",
    "    lat = candidate['geometry']['location']['lat']\n",
    "    lng = candidate['geometry']['location']['lng']\n",
    "    name = candidate['name']\n",
    "    formatted_address = candidate['formatted_address']\n",
    "\n",
    "    # Once we have that information, we can create a Point geometry for the geodataframe.\n",
    "    point = Point(lng, lat)\n",
    "\n",
    "    #We can then append the information to the marker_gdf.\n",
    "    marker_gdf = marker_gdf.append({'name': name, 'formatted_address': formatted_address, 'geometry': point}, ignore_index=True)\n",
    "    \n",
    "#Finally, we need to establish the coordinte system for the dataframe since it currently does not have one defined.    \n",
    "marker_gdf.set_crs(epsg=4326, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next, we need to convert the first gdf to the same coordinate system as our second.\n",
    "newgdf=gdf.to_crs(epsg=4326)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to ensure that the coordinate systems for both are the same.\n",
    "marker_gdf.crs=newgdf.crs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we will perform a spatial join between gdf (polygons) and marker_gdf (points) so that the attributes of gdf are appended to marker_gdf.\n",
    "spatial_join_result = gpd.sjoin(marker_gdf, newgdf, how=\"left\", predicate=\"within\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>formatted_address</th>\n",
       "      <th>geometry</th>\n",
       "      <th>index_right</th>\n",
       "      <th>CO_CODE</th>\n",
       "      <th>CO_NAME</th>\n",
       "      <th>CO_NAME_FU</th>\n",
       "      <th>CO_ABBREV</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shape_Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>713 S Washington Ave Ste 101, Minneapolis, MN ...</td>\n",
       "      <td>POINT (-93.25799 44.97717)</td>\n",
       "      <td>6</td>\n",
       "      <td>053</td>\n",
       "      <td>HENNEPIN</td>\n",
       "      <td>Hennepin County</td>\n",
       "      <td>HENN</td>\n",
       "      <td>190173.30393</td>\n",
       "      <td>1.569918e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name                                  formatted_address  \\\n",
       "0  Starbucks  713 S Washington Ave Ste 101, Minneapolis, MN ...   \n",
       "\n",
       "                     geometry  index_right CO_CODE   CO_NAME       CO_NAME_FU  \\\n",
       "0  POINT (-93.25799 44.97717)            6     053  HENNEPIN  Hennepin County   \n",
       "\n",
       "  CO_ABBREV    Shape_Leng    Shape_Area  \n",
       "0      HENN  190173.30393  1.569918e+09  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Next, let's take a look at the results of our spatial join\n",
    "spatial_join_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_143/4239984448.py:2: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  spatial_join_result.to_file(\"output_shapefile.shp\")\n"
     ]
    }
   ],
   "source": [
    "#Next we need to save this data in a geodatabase.\n",
    "#First, let's save our dataset as a shapefile for easier storage.\n",
    "spatial_join_result.to_file(\"output_shapefile.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, October 10, 2023 8:05:52 PM\",\"Succeeded at Tuesday, October 10, 2023 8:05:53 PM (Elapsed Time: 0.23 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:/Lab1GDB.gdb'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Next, let's create a geodatabase to save our data i.\n",
    "arcpy.CreateFileGDB_management(\"C:\", \"Lab1GDB.gdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, October 10, 2023 8:11:35 PM\",\"Succeeded at Tuesday, October 10, 2023 8:11:35 PM (Elapsed Time: 0.45 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:/Lab1GDB.gdb/MyFeatureClass'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, we can save the shape file to the goedatabase using arcpy.\n",
    "# We first call in the geodatabase.\n",
    "workspace = r'C:/Lab1GDB.gdb'\n",
    "arcpy.env.workspace = workspace\n",
    "\n",
    "# Then we call in  our shapefile.\n",
    "shapefile_path = \"output_shapefile.shp\"\n",
    "\n",
    "# We then specify the name for the feature class within the FGDB.\n",
    "feature_class_name = 'MyFeatureClass'\n",
    "\n",
    "# The we copy the shapefile to the FGDB.\n",
    "arcpy.CopyFeatures_management(shapefile_path, os.path.join(workspace, feature_class_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "esriNotebookRuntime": {
   "notebookRuntimeName": "ArcGIS Notebook Python 3 Advanced",
   "notebookRuntimeVersion": "8.0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
